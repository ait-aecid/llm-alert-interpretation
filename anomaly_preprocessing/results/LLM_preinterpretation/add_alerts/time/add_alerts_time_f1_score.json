[
    {
        "run_nr": "45_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.8181818181818183,
        "accuracy": 0.82,
        "precision": 0.826530612244898
    },
    {
        "run_nr": "40_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.8159203980099502,
        "accuracy": 0.815,
        "precision": 0.8118811881188119
    },
    {
        "run_nr": "10_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.8118811881188118,
        "accuracy": 0.81,
        "precision": 0.803921568627451
    },
    {
        "run_nr": "25_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.81,
        "accuracy": 0.81,
        "precision": 0.81
    },
    {
        "run_nr": "5_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.81,
        "accuracy": 0.81,
        "precision": 0.81
    },
    {
        "run_nr": "35_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.8059701492537314,
        "accuracy": 0.805,
        "precision": 0.801980198019802
    },
    {
        "run_nr": "50_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.803921568627451,
        "accuracy": 0.8,
        "precision": 0.7884615384615384
    },
    {
        "run_nr": "20_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.801980198019802,
        "accuracy": 0.8,
        "precision": 0.7941176470588235
    },
    {
        "run_nr": "15_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.7979797979797979,
        "accuracy": 0.8,
        "precision": 0.8061224489795918
    },
    {
        "run_nr": "30_run",
        "llm": "chatgpt",
        "dataset": "aminer",
        "f1": 0.792079207920792,
        "accuracy": 0.79,
        "precision": 0.7843137254901961
    },
    {
        "run_nr": "10_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.7317073170731707,
        "accuracy": 0.78,
        "precision": 0.9375
    },
    {
        "run_nr": "15_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.7317073170731707,
        "accuracy": 0.78,
        "precision": 0.9375
    },
    {
        "run_nr": "5_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.7239263803680981,
        "accuracy": 0.775,
        "precision": 0.9365079365079365
    },
    {
        "run_nr": "45_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.7017543859649124,
        "accuracy": 0.745,
        "precision": 0.8450704225352113
    },
    {
        "run_nr": "50_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.7017543859649124,
        "accuracy": 0.745,
        "precision": 0.8450704225352113
    },
    {
        "run_nr": "20_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.6987951807228915,
        "accuracy": 0.75,
        "precision": 0.8787878787878788
    },
    {
        "run_nr": "35_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.6941176470588235,
        "accuracy": 0.74,
        "precision": 0.8428571428571429
    },
    {
        "run_nr": "40_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.6941176470588235,
        "accuracy": 0.74,
        "precision": 0.8428571428571429
    },
    {
        "run_nr": "25_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.6863905325443788,
        "accuracy": 0.735,
        "precision": 0.8405797101449275
    },
    {
        "run_nr": "30_run",
        "llm": "gemini",
        "dataset": "wazuh",
        "f1": 0.6863905325443788,
        "accuracy": 0.735,
        "precision": 0.8405797101449275
    },
    {
        "run_nr": "5_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.6794871794871796,
        "accuracy": 0.75,
        "precision": 0.9464285714285714
    },
    {
        "run_nr": "15_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.679245283018868,
        "accuracy": 0.745,
        "precision": 0.9152542372881356
    },
    {
        "run_nr": "25_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.675,
        "accuracy": 0.74,
        "precision": 0.9
    },
    {
        "run_nr": "10_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.6708860759493671,
        "accuracy": 0.74,
        "precision": 0.9137931034482759
    },
    {
        "run_nr": "50_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.6666666666666667,
        "accuracy": 0.735,
        "precision": 0.8983050847457628
    },
    {
        "run_nr": "20_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.6666666666666666,
        "accuracy": 0.74,
        "precision": 0.9285714285714286
    },
    {
        "run_nr": "40_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6626506024096386,
        "accuracy": 0.72,
        "precision": 0.8333333333333334
    },
    {
        "run_nr": "45_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6626506024096386,
        "accuracy": 0.72,
        "precision": 0.8333333333333334
    },
    {
        "run_nr": "50_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6626506024096386,
        "accuracy": 0.72,
        "precision": 0.8333333333333334
    },
    {
        "run_nr": "10_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6586826347305389,
        "accuracy": 0.715,
        "precision": 0.8208955223880597
    },
    {
        "run_nr": "25_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6545454545454545,
        "accuracy": 0.715,
        "precision": 0.8307692307692308
    },
    {
        "run_nr": "30_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6545454545454545,
        "accuracy": 0.715,
        "precision": 0.8307692307692308
    },
    {
        "run_nr": "35_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6545454545454545,
        "accuracy": 0.715,
        "precision": 0.8307692307692308
    },
    {
        "run_nr": "15_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6506024096385542,
        "accuracy": 0.71,
        "precision": 0.8181818181818182
    },
    {
        "run_nr": "20_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6506024096385542,
        "accuracy": 0.71,
        "precision": 0.8181818181818182
    },
    {
        "run_nr": "45_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.6451612903225806,
        "accuracy": 0.725,
        "precision": 0.9090909090909091
    },
    {
        "run_nr": "35_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.6329113924050632,
        "accuracy": 0.71,
        "precision": 0.8620689655172413
    },
    {
        "run_nr": "30_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.632258064516129,
        "accuracy": 0.715,
        "precision": 0.8909090909090909
    },
    {
        "run_nr": "40_run",
        "llm": "chatgpt",
        "dataset": "wazuh",
        "f1": 0.624203821656051,
        "accuracy": 0.705,
        "precision": 0.8596491228070176
    },
    {
        "run_nr": "5_run",
        "llm": "gemini",
        "dataset": "aminer",
        "f1": 0.6075949367088608,
        "accuracy": 0.69,
        "precision": 0.8275862068965517
    }
]